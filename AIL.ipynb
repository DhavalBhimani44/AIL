{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2f5fc08-c758-4110-ad64-a0fa45d21991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DFS Traversal: A B C D E "
     ]
    }
   ],
   "source": [
    "# 1. Implement Recursive Depth First Search Algorithm. Read the undirected unweighted graph from a .csv file. \n",
    "\n",
    "import csv\n",
    "\n",
    "def read_graph_from_csv(filename):\n",
    "    graph = {}\n",
    "    with open(filename, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            node1, node2 = row\n",
    "            if node1 not in graph:\n",
    "                graph[node1] = []\n",
    "            if node2 not in graph:\n",
    "                graph[node2] = []\n",
    "            graph[node1].append(node2)\n",
    "            graph[node2].append(node1)\n",
    "    return graph\n",
    "\n",
    "def dfs_recursive(graph, node, visited):\n",
    "    visited.add(node)\n",
    "    print(node, end = ' ')\n",
    "    for neighbor in graph[node]:\n",
    "        if neighbor not in visited:\n",
    "            dfs_recursive(graph, neighbor, visited)\n",
    "\n",
    "def main():\n",
    "    filename = 'edges.csv' \n",
    "    graph = read_graph_from_csv(filename)\n",
    "    visited = set()\n",
    "    start_node = list(graph.keys())[0]\n",
    "    print(\"DFS Traversal:\", end=' ')\n",
    "    dfs_recursive(graph, start_node, visited)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88db5dcd-58c0-4ac3-be00-5c9d9b0403c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number of edges:  5\n",
      "Enter edge (node1 node2):  0 1\n",
      "Enter edge (node1 node2):  0 2\n",
      "Enter edge (node1 node2):  1 2\n",
      "Enter edge (node1 node2):  2 3\n",
      "Enter edge (node1 node2):  2 4\n",
      "Enter start node:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DFS Traversal: 0 2 4 3 1 "
     ]
    }
   ],
   "source": [
    "# 2. Implement Non-Recursive Depth First Search Algorithm. Read the undirected unweighted graph from user. \n",
    "\n",
    "def read_graph_from_user():\n",
    "    graph = {}\n",
    "    n = int(input(\"Enter number of edges: \"))\n",
    "    for _ in range(n):\n",
    "        node1, node2 = input(\"Enter edge (node1 node2): \").split()\n",
    "        if node1 not in graph:\n",
    "            graph[node1] = []\n",
    "        if node2 not in graph:\n",
    "            graph[node2] = []\n",
    "        graph[node1].append(node2)\n",
    "        graph[node2].append(node1)\n",
    "    return graph\n",
    "\n",
    "def dfs_non_recursive(graph, start_node):\n",
    "    visited = set()\n",
    "    stack = [start_node]\n",
    "    while stack:\n",
    "        node = stack.pop()\n",
    "        if node not in visited:\n",
    "            visited.add(node)\n",
    "            print(node, end=' ')\n",
    "            for neighbor in graph[node]:\n",
    "                if neighbor not in visited:\n",
    "                    stack.append(neighbor)\n",
    "\n",
    "def main():\n",
    "    graph = read_graph_from_user()\n",
    "    start_node = input(\"Enter start node: \")\n",
    "    print(\"DFS Traversal:\", end=' ')\n",
    "    dfs_non_recursive(graph, start_node)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4573f780-af87-4204-b551-d4559771a787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number of edges:  5\n",
      "Enter edge (node1 node2):  0 1\n",
      "Enter edge (node1 node2):  0 2\n",
      "Enter edge (node1 node2):  1 2\n",
      "Enter edge (node1 node2):  2 3\n",
      "Enter edge (node1 node2):  2 4\n",
      "Enter start node:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFS Traversal: 0 1 2 3 4 "
     ]
    }
   ],
   "source": [
    "# 3. Implement Breadth First Search Algorithm. Read the undirected unweighted graph from user. \n",
    "\n",
    "from collections import deque\n",
    "\n",
    "def read_graph_from_user():\n",
    "    graph = {}\n",
    "    n = int(input(\"Enter number of edges: \"))\n",
    "    for _ in range(n):\n",
    "        node1, node2 = input(\"Enter edge (node1 node2): \").split()\n",
    "        if node1 not in graph:\n",
    "            graph[node1] = []\n",
    "        if node2 not in graph:\n",
    "            graph[node2] = []\n",
    "        graph[node1].append(node2)\n",
    "        graph[node2].append(node1)\n",
    "    return graph\n",
    "\n",
    "def bfs(graph, start_node):\n",
    "    visited = set()\n",
    "    queue = deque([start_node])\n",
    "    visited.add(start_node)\n",
    "    while queue:\n",
    "        node = queue.popleft()\n",
    "        print(node, end=' ')\n",
    "        for neighbor in graph[node]:\n",
    "            if neighbor not in visited:\n",
    "                visited.add(neighbor)\n",
    "                queue.append(neighbor)\n",
    "\n",
    "def main():\n",
    "    graph = read_graph_from_user()\n",
    "    start_node = input(\"Enter start node: \")\n",
    "    print(\"BFS Traversal:\", end=' ')\n",
    "    bfs(graph, start_node)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c677add-cc8d-4685-bd35-023903156b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number of edges:  6\n",
      "Enter edge (node1 node2):  A B\n",
      "Enter edge (node1 node2):  A C\n",
      "Enter edge (node1 node2):  B D\n",
      "Enter edge (node1 node2):  C D\n",
      "Enter edge (node1 node2):  C E\n",
      "Enter edge (node1 node2):  E G\n",
      "Enter all nodes (space-separated):  A B C D E G\n",
      "Enter heuristic for A:  6\n",
      "Enter heuristic for B:  4\n",
      "Enter heuristic for C:  5\n",
      "Enter heuristic for D:  2\n",
      "Enter heuristic for E:  3\n",
      "Enter heuristic for G:  0\n",
      "Enter start node:  A\n",
      "Enter goal node:  G\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best First Search Path: A B D C E G "
     ]
    }
   ],
   "source": [
    "# 4. Implement Best First Search Algorithm. Read the directed unweighted graph and the heuristic values from user.\n",
    "\n",
    "from queue import PriorityQueue\n",
    "\n",
    "def read_graph_and_heuristics():\n",
    "    graph = {}\n",
    "    heuristics = {}\n",
    "    n = int(input(\"Enter number of edges: \"))\n",
    "    for _ in range(n):\n",
    "        node1, node2 = input(\"Enter edge (node1 node2): \").split()\n",
    "        if node1 not in graph:\n",
    "            graph[node1] = []\n",
    "        graph[node1].append(node2)\n",
    "    nodes = input(\"Enter all nodes (space-separated): \").split()\n",
    "    for node in nodes:\n",
    "        h = int(input(f\"Enter heuristic for {node}: \"))\n",
    "        heuristics[node] = h\n",
    "    return graph, heuristics\n",
    "\n",
    "def best_first_search(graph, start, goal, heuristics):\n",
    "    visited = set()\n",
    "    pq = PriorityQueue()\n",
    "    pq.put((heuristics[start], start))\n",
    "    while not pq.empty():\n",
    "        _, node = pq.get()\n",
    "        if node in visited:\n",
    "            continue\n",
    "        print(node, end=' ')\n",
    "        visited.add(node)\n",
    "        if node == goal:\n",
    "            break\n",
    "        for neighbor in graph.get(node, []):\n",
    "            if neighbor not in visited:\n",
    "                pq.put((heuristics[neighbor], neighbor))\n",
    "\n",
    "def main():\n",
    "    graph, heuristics = read_graph_and_heuristics()\n",
    "    start = input(\"Enter start node: \")\n",
    "    goal = input(\"Enter goal node: \")\n",
    "    print(\"Best First Search Path:\", end=' ')\n",
    "    best_first_search(graph, start, goal, heuristics)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6028860-a410-4b3b-9965-0d66051039d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number of edges:  7\n",
      "Enter edge (node1 node2 weight):  S A 2\n",
      "Enter edge (node1 node2 weight):  S B 3\n",
      "Enter edge (node1 node2 weight):  A C 4\n",
      "Enter edge (node1 node2 weight):  B D 5\n",
      "Enter edge (node1 node2 weight):  C G 2\n",
      "Enter edge (node1 node2 weight):  D G 3\n",
      "Enter edge (node1 node2 weight):  B E 1\n",
      "Enter all nodes (space-separated):  S A B C D E G  \n",
      "Enter heuristic for S:  7\n",
      "Enter heuristic for A:  6\n",
      "Enter heuristic for B:  2\n",
      "Enter heuristic for C:  4\n",
      "Enter heuristic for D:  4\n",
      "Enter heuristic for E:  6\n",
      "Enter heuristic for G:  0\n",
      "Enter start node:  S\n",
      "Enter goal node:  G\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best First Search Path: S B D G "
     ]
    }
   ],
   "source": [
    "# 5. Implement Best First Search Algorithm. Read the undirected weighted graph and the heuristic values from user\n",
    "\n",
    "from queue import PriorityQueue\n",
    "\n",
    "def read_graph_and_heuristics():\n",
    "    graph = {}\n",
    "    heuristics = {}\n",
    "    n = int(input(\"Enter number of edges: \"))\n",
    "    for _ in range(n):\n",
    "        node1, node2, weight = input(\"Enter edge (node1 node2 weight): \").split()\n",
    "        weight = int(weight)\n",
    "        if node1 not in graph:\n",
    "            graph[node1] = []\n",
    "        if node2 not in graph:\n",
    "            graph[node2] = []\n",
    "        graph[node1].append((node2, weight))\n",
    "        graph[node2].append((node1, weight))\n",
    "    nodes = input(\"Enter all nodes (space-separated): \").split()\n",
    "    for node in nodes:\n",
    "        h = int(input(f\"Enter heuristic for {node}: \"))\n",
    "        heuristics[node] = h\n",
    "    return graph, heuristics\n",
    "\n",
    "def best_first_search(graph, start, goal, heuristics):\n",
    "    visited = set()\n",
    "    pq = PriorityQueue()\n",
    "    pq.put((heuristics[start], start))\n",
    "    while not pq.empty():\n",
    "        _, node = pq.get()\n",
    "        if node in visited:\n",
    "            continue\n",
    "        print(node, end=' ')\n",
    "        visited.add(node)\n",
    "        if node == goal:\n",
    "            break\n",
    "        for neighbor, _ in graph.get(node, []):\n",
    "            if neighbor not in visited:\n",
    "                pq.put((heuristics[neighbor], neighbor))\n",
    "\n",
    "def main():\n",
    "    graph, heuristics = read_graph_and_heuristics()\n",
    "    start = input(\"Enter start node: \")\n",
    "    goal = input(\"Enter goal node: \")\n",
    "    print(\"Best First Search Path:\", end=' ')\n",
    "    best_first_search(graph, start, goal, heuristics)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbc9215-6b51-42ba-ae05-95f1d51361c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Implement Best First Search Algorithm. Read the undirected unweighted graph and the heuristic values from user.\n",
    "\n",
    "from queue import PriorityQueue\n",
    "\n",
    "def read_graph_and_heuristics():\n",
    "    graph = {}\n",
    "    heuristics = {}\n",
    "    n = int(input(\"Enter number of edges: \"))\n",
    "    for _ in range(n):\n",
    "        node1, node2 = input(\"Enter edge (node1 node2): \").split()\n",
    "        if node1 not in graph:\n",
    "            graph[node1] = []\n",
    "        if node2 not in graph:\n",
    "            graph[node2] = []\n",
    "        graph[node1].append(node2)\n",
    "        graph[node2].append(node1)\n",
    "    nodes = input(\"Enter all nodes (space-separated): \").split()\n",
    "    for node in nodes:\n",
    "        h = int(input(f\"Enter heuristic for {node}: \"))\n",
    "        heuristics[node] = h\n",
    "    return graph, heuristics\n",
    "\n",
    "def best_first_search(graph, start, goal, heuristics):\n",
    "    visited = set()\n",
    "    pq = PriorityQueue()\n",
    "    pq.put((heuristics[start], start))\n",
    "    while not pq.empty():\n",
    "        _, node = pq.get()\n",
    "        if node in visited:\n",
    "            continue\n",
    "        print(node, end=' ')\n",
    "        visited.add(node)\n",
    "        if node == goal:\n",
    "            break\n",
    "        for neighbor in graph.get(node, []):\n",
    "            if neighbor not in visited:\n",
    "                pq.put((heuristics[neighbor], neighbor))\n",
    "\n",
    "def main():\n",
    "    graph, heuristics = read_graph_and_heuristics()\n",
    "    start = input(\"Enter start node: \")\n",
    "    goal = input(\"Enter goal node: \")\n",
    "    print(\"Best First Search Path:\", end=' ')\n",
    "    best_first_search(graph, start, goal, heuristics)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fc81ee-ad23-44f9-a2e5-3a1b5974c45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Implement Best First Search Algorithm. Read the directed weighted graph and the heuristic values from user.\n",
    "\n",
    "from queue import PriorityQueue\n",
    "\n",
    "def read_graph_and_heuristics():\n",
    "    graph = {}\n",
    "    heuristics = {}\n",
    "    n = int(input(\"Enter number of edges: \"))\n",
    "    for _ in range(n):\n",
    "        node1, node2, weight = input(\"Enter edge (node1 node2 weight): \").split()\n",
    "        weight = int(weight)\n",
    "        if node1 not in graph:\n",
    "            graph[node1] = []\n",
    "        graph[node1].append((node2, weight))\n",
    "    nodes = input(\"Enter all nodes (space-separated): \").split()\n",
    "    for node in nodes:\n",
    "        h = int(input(f\"Enter heuristic for {node}: \"))\n",
    "        heuristics[node] = h\n",
    "    return graph, heuristics\n",
    "\n",
    "def best_first_search(graph, start, goal, heuristics):\n",
    "    visited = set()\n",
    "    pq = PriorityQueue()\n",
    "    pq.put((heuristics[start], start))\n",
    "    while not pq.empty():\n",
    "        _, node = pq.get()\n",
    "        if node in visited:\n",
    "            continue\n",
    "        print(node, end=' ')\n",
    "        visited.add(node)\n",
    "        if node == goal:\n",
    "            break\n",
    "        for neighbor, _ in graph.get(node, []):\n",
    "            if neighbor not in visited:\n",
    "                pq.put((heuristics[neighbor], neighbor))\n",
    "\n",
    "def main():\n",
    "    graph, heuristics = read_graph_and_heuristics()\n",
    "    start = input(\"Enter start node: \")\n",
    "    goal = input(\"Enter goal node: \")\n",
    "    print(\"Best First Search Path:\", end=' ')\n",
    "    best_first_search(graph, start, goal, heuristics)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44f6164c-fc71-4284-af93-4454c350ce4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter start node:  A\n",
      "Enter goal node:  D\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A* Path: A -> B -> C -> D\n"
     ]
    }
   ],
   "source": [
    "# 8. Implement A* algorithm. Read directed weighted graph and heuristic values from a .csv file. \n",
    "\n",
    "import csv\n",
    "from queue import PriorityQueue\n",
    "\n",
    "def read_graph_and_heuristics(filename):\n",
    "    graph = {}\n",
    "    heuristics = {}\n",
    "    with open(filename, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            if not row or row[0].startswith('#') or row[0] == 'node1':\n",
    "                continue\n",
    "            try:\n",
    "                if len(row) == 2:  \n",
    "                    node, h = row\n",
    "                    heuristics[node] = int(h)\n",
    "                elif len(row) == 3: \n",
    "                    node1, node2, weight = row\n",
    "                    if node1 not in graph:\n",
    "                        graph[node1] = []\n",
    "                    graph[node1].append((node2, int(weight)))\n",
    "            except ValueError:\n",
    "                continue\n",
    "    return graph, heuristics\n",
    "\n",
    "def a_star(graph, start, goal, heuristics):\n",
    "    pq = PriorityQueue()\n",
    "    pq.put((0, start))\n",
    "    g_score = {start: 0}\n",
    "    came_from = {}\n",
    "    while not pq.empty():\n",
    "        _, node = pq.get()\n",
    "        if node == goal:\n",
    "            path = []\n",
    "            while node in came_from:\n",
    "                path.append(node)\n",
    "                node = came_from[node]\n",
    "            path.append(start)\n",
    "            return path[::-1]\n",
    "        for neighbor, weight in graph.get(node, []):\n",
    "            tentative_g = g_score[node] + weight\n",
    "            if neighbor not in g_score or tentative_g < g_score[neighbor]:\n",
    "                came_from[neighbor] = node\n",
    "                g_score[neighbor] = tentative_g\n",
    "                f_score = tentative_g + heuristics.get(neighbor, 0)\n",
    "                pq.put((f_score, neighbor))\n",
    "    return []\n",
    "\n",
    "def main():\n",
    "    filename = 'graph.csv' \n",
    "    graph, heuristics = read_graph_and_heuristics(filename)\n",
    "    start = input(\"Enter start node: \")\n",
    "    goal = input(\"Enter goal node: \")\n",
    "    path = a_star(graph, start, goal, heuristics)\n",
    "    print(\"A* Path:\", ' -> '.join(path) if path else \"No path found\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0dfe9269-cc98-4017-8a39-d7ea5d45d8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number of edges:  6\n",
      "Enter edge (node1 node2 weight):  A B 2\n",
      "Enter edge (node1 node2 weight):  A C 3\n",
      "Enter edge (node1 node2 weight):  B C 5\n",
      "Enter edge (node1 node2 weight):  B D 7\n",
      "Enter edge (node1 node2 weight):  C D 9\n",
      "Enter edge (node1 node2 weight):  C E 5\n",
      "Enter all nodes (space-separated):  A B C D E \n",
      "Enter heuristic for A:  5\n",
      "Enter heuristic for B:  4\n",
      "Enter heuristic for C:  3\n",
      "Enter heuristic for D:  7\n",
      "Enter heuristic for E:  9\n",
      "Enter start node:  A\n",
      "Enter goal node:  E\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A* Path: A -> C -> E\n"
     ]
    }
   ],
   "source": [
    "# 9. Implement A* algorithm. Read directed weighted graph and heuristic values from user. \n",
    "\n",
    "from queue import PriorityQueue\n",
    "\n",
    "def read_graph_and_heuristics():\n",
    "    graph = {}\n",
    "    heuristics = {}\n",
    "    n = int(input(\"Enter number of edges: \"))\n",
    "    for _ in range(n):\n",
    "        node1, node2, weight = input(\"Enter edge (node1 node2 weight): \").split()\n",
    "        if node1 not in graph:\n",
    "            graph[node1] = []\n",
    "        graph[node1].append((node2, int(weight)))\n",
    "    nodes = input(\"Enter all nodes (space-separated): \").split()\n",
    "    for node in nodes:\n",
    "        h = int(input(f\"Enter heuristic for {node}: \"))\n",
    "        heuristics[node] = h\n",
    "    return graph, heuristics\n",
    "\n",
    "def a_star(graph, start, goal, heuristics):\n",
    "    pq = PriorityQueue()\n",
    "    pq.put((0, start))\n",
    "    g_score = {start: 0}\n",
    "    came_from = {}\n",
    "    while not pq.empty():\n",
    "        _, node = pq.get()\n",
    "        if node == goal:\n",
    "            path = []\n",
    "            while node in came_from:\n",
    "                path.append(node)\n",
    "                node = came_from[node]\n",
    "            path.append(start)\n",
    "            return path[::-1]\n",
    "        for neighbor, weight in graph.get(node, []):\n",
    "            tentative_g = g_score[node] + weight\n",
    "            if neighbor not in g_score or tentative_g < g_score[neighbor]:\n",
    "                came_from[neighbor] = node\n",
    "                g_score[neighbor] = tentative_g\n",
    "                f_score = tentative_g + heuristics.get(neighbor, 0)\n",
    "                pq.put((f_score, neighbor))\n",
    "    return []\n",
    "\n",
    "def main():\n",
    "    graph, heuristics = read_graph_and_heuristics()\n",
    "    start = input(\"Enter start node: \")\n",
    "    goal = input(\"Enter goal node: \")\n",
    "    path = a_star(graph, start, goal, heuristics)\n",
    "    print(\"A* Path:\", ' -> '.join(path) if path else \"No path found\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56282610-7cc5-4a7c-9d9b-024ebe1ffab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter start node:  A\n",
      "Enter goal node:  E\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A* Path: A -> E\n"
     ]
    }
   ],
   "source": [
    "# 10. Implement A* algorithm. Read undirected weighted graph and heuristic values from a .csv file. \n",
    "\n",
    "# Create graph.csv\n",
    "with open('graph.csv', 'w') as f:\n",
    "    f.write('# Edges: node1,node2,weight\\nnode1,node2,weight\\nA,B,2\\nA,E,5\\nB,C,3\\nB,E,2\\nC,D,1\\nD,E,4\\n# Heuristics: node,h_value\\nA,10\\nB,8\\nC,5\\nD,3\\nE,0')\n",
    "\n",
    "import csv\n",
    "from queue import PriorityQueue\n",
    "\n",
    "def read_graph_and_heuristics(filename):\n",
    "    graph = {}\n",
    "    heuristics = {}\n",
    "    with open(filename, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            if not row or row[0].startswith('#') or row[0] == 'node1':\n",
    "                continue\n",
    "            try:\n",
    "                if len(row) == 2:\n",
    "                    node, h = row\n",
    "                    heuristics[node] = int(h)\n",
    "                elif len(row) == 3:\n",
    "                    node1, node2, weight = row\n",
    "                    if node1 not in graph:\n",
    "                        graph[node1] = []\n",
    "                    if node2 not in graph:\n",
    "                        graph[node2] = []\n",
    "                    graph[node1].append((node2, int(weight)))\n",
    "                    graph[node2].append((node1, int(weight)))\n",
    "            except ValueError:\n",
    "                continue\n",
    "    return graph, heuristics\n",
    "\n",
    "def a_star(graph, start, goal, heuristics):\n",
    "    pq = PriorityQueue()\n",
    "    pq.put((0, start))\n",
    "    g_score = {start: 0}\n",
    "    came_from = {}\n",
    "    while not pq.empty():\n",
    "        _, node = pq.get()\n",
    "        if node == goal:\n",
    "            path = []\n",
    "            while node in came_from:\n",
    "                path.append(node)\n",
    "                node = came_from[node]\n",
    "            path.append(start)\n",
    "            return path[::-1]\n",
    "        for neighbor, weight in graph.get(node, []):\n",
    "            tentative_g = g_score[node] + weight\n",
    "            if neighbor not in g_score or tentative_g < g_score[neighbor]:\n",
    "                came_from[neighbor] = node\n",
    "                g_score[neighbor] = tentative_g\n",
    "                f_score = tentative_g + heuristics.get(neighbor, 0)\n",
    "                pq.put((f_score, neighbor))\n",
    "    return []\n",
    "\n",
    "def main():\n",
    "    filename = 'graph.csv'\n",
    "    graph, heuristics = read_graph_and_heuristics(filename)\n",
    "    start = input(\"Enter start node: \")\n",
    "    goal = input(\"Enter goal node: \")\n",
    "    path = a_star(graph, start, goal, heuristics)\n",
    "    print(\"A* Path:\", ' -> '.join(path) if path else \"No path found\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f53790e-88e3-47ff-a6ba-c7f3241eab40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number of edges:  4\n",
      "Enter edge (node1 node2 weight):  A B 2\n",
      "Enter edge (node1 node2 weight):  A C 3\n",
      "Enter edge (node1 node2 weight):  B C 6\n",
      "Enter edge (node1 node2 weight):  C D 3\n",
      "Enter all nodes (space-separated):  A B C D \n",
      "Enter heuristic for A:  4\n",
      "Enter heuristic for B:  5\n",
      "Enter heuristic for C:  2\n",
      "Enter heuristic for D:  3\n",
      "Enter start node:  A \n",
      "Enter goal node:  D\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A* Path: No path found\n"
     ]
    }
   ],
   "source": [
    "# 11. Implement A* algorithm. Read undirected weighted graph and heuristic values from user. \n",
    "\n",
    "from queue import PriorityQueue\n",
    "\n",
    "def read_graph_and_heuristics():\n",
    "    graph = {}\n",
    "    heuristics = {}\n",
    "    n = int(input(\"Enter number of edges: \"))\n",
    "    for _ in range(n):\n",
    "        node1, node2, weight = input(\"Enter edge (node1 node2 weight): \").split()\n",
    "        if node1 not in graph:\n",
    "            graph[node1] = []\n",
    "        if node2 not in graph:\n",
    "            graph[node2] = []\n",
    "        graph[node1].append((node2, int(weight)))\n",
    "        graph[node2].append((node1, int(weight)))\n",
    "    nodes = input(\"Enter all nodes (space-separated): \").split()\n",
    "    for node in nodes:\n",
    "        h = int(input(f\"Enter heuristic for {node}: \"))\n",
    "        heuristics[node] = h\n",
    "    return graph, heuristics\n",
    "\n",
    "def a_star(graph, start, goal, heuristics):\n",
    "    pq = PriorityQueue()\n",
    "    pq.put((0, start))\n",
    "    g_score = {start: 0}\n",
    "    came_from = {}\n",
    "    while not pq.empty():\n",
    "        _, node = pq.get()\n",
    "        if node == goal:\n",
    "            path = []\n",
    "            while node in came_from:\n",
    "                path.append(node)\n",
    "                node = came_from[node]\n",
    "            path.append(start)\n",
    "            return path[::-1]\n",
    "        for neighbor, weight in graph.get(node, []):\n",
    "            tentative_g = g_score[node] + weight\n",
    "            if neighbor not in g_score or tentative_g < g_score[neighbor]:\n",
    "                came_from[neighbor] = node\n",
    "                g_score[neighbor] = tentative_g\n",
    "                f_score = tentative_g + heuristics.get(neighbor, 0)\n",
    "                pq.put((f_score, neighbor))\n",
    "    return []\n",
    "\n",
    "def main():\n",
    "    graph, heuristics = read_graph_and_heuristics()\n",
    "    start = input(\"Enter start node: \")\n",
    "    goal = input(\"Enter goal node: \")\n",
    "    path = a_star(graph, start, goal, heuristics)\n",
    "    print(\"A* Path:\", ' -> '.join(path) if path else \"No path found\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3dff3960-9355-4792-9d55-d896642200b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fuzzy Set A: {'x1': 0.8, 'x2': 0.4, 'x3': 0.6}\n",
      "Fuzzy Set B: {'x1': 0.5, 'x2': 0.7, 'x3': 0.2}\n",
      "Fuzzy Set C: {'x1': 0.3, 'x2': 0.9, 'x3': 0.5}\n",
      "Union (A ∪ B ∪ C): {'x2': 0.9, 'x3': 0.6, 'x1': 0.8}\n",
      "Intersection (A ∩ B ∩ C): {'x2': 0.4, 'x3': 0.2, 'x1': 0.3}\n",
      "Complement A': {'x2': 0.6, 'x3': 0.4, 'x1': 0.19999999999999996}\n",
      "Complement B': {'x2': 0.30000000000000004, 'x3': 0.8, 'x1': 0.5}\n",
      "Complement C': {'x2': 0.09999999999999998, 'x3': 0.5, 'x1': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# 12. Implement Fuzzy set operations – union, intersection and complement. Demonstrate these operations with 3 fuzzy sets.\n",
    "\n",
    "def fuzzy_union(set1, set2):\n",
    "    return {k: max(set1.get(k, 0), set2.get(k, 0)) for k in set1.keys() | set2.keys()}\n",
    "\n",
    "def fuzzy_intersection(set1, set2):\n",
    "    return {k: min(set1.get(k, 0), set2.get(k, 0)) for k in set1.keys() & set2.keys()}\n",
    "\n",
    "def fuzzy_complement(set1, universe):\n",
    "    return {k: 1 - set1.get(k, 0) for k in universe}\n",
    "\n",
    "def main():\n",
    "    # Example fuzzy sets\n",
    "    A = {'x1': 0.8, 'x2': 0.4, 'x3': 0.6}\n",
    "    B = {'x1': 0.5, 'x2': 0.7, 'x3': 0.2}\n",
    "    C = {'x1': 0.3, 'x2': 0.9, 'x3': 0.5}\n",
    "    universe = {'x1', 'x2', 'x3'}\n",
    "    \n",
    "    print(\"Fuzzy Set A:\", A)\n",
    "    print(\"Fuzzy Set B:\", B)\n",
    "    print(\"Fuzzy Set C:\", C)\n",
    "    \n",
    "    # Union\n",
    "    union_AB = fuzzy_union(A, B)\n",
    "    union_ABC = fuzzy_union(union_AB, C)\n",
    "    print(\"Union (A ∪ B ∪ C):\", union_ABC)\n",
    "    \n",
    "    # Intersection\n",
    "    inter_AB = fuzzy_intersection(A, B)\n",
    "    inter_ABC = fuzzy_intersection(inter_AB, C)\n",
    "    print(\"Intersection (A ∩ B ∩ C):\", inter_ABC)\n",
    "    \n",
    "    # Complement\n",
    "    comp_A = fuzzy_complement(A, universe)\n",
    "    comp_B = fuzzy_complement(B, universe)\n",
    "    comp_C = fuzzy_complement(C, universe)\n",
    "    print(\"Complement A':\", comp_A)\n",
    "    print(\"Complement B':\", comp_B)\n",
    "    print(\"Complement C':\", comp_C)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06801228-303f-43ef-a916-e0f8f00e0b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fuzzy Set A: {'x1': 0.8, 'x2': 0.4, 'x3': 0.6}\n",
      "Fuzzy Set B: {'x1': 0.5, 'x2': 0.7, 'x3': 0.2}\n",
      "(A ∪ B)': {'x2': 0.30000000000000004, 'x3': 0.4, 'x1': 0.19999999999999996}\n",
      "A' ∩ B': {'x2': 0.30000000000000004, 'x3': 0.4, 'x1': 0.19999999999999996}\n",
      "De Morgan's Law holds: True\n"
     ]
    }
   ],
   "source": [
    "# 13. Implement Fuzzy set operations – union, intersection and complement. Demonstrate De Morgan’s Law ( Complement of Union) with 2 fuzzy sets. \n",
    "\n",
    "def fuzzy_union(set1, set2):\n",
    "    return {k: max(set1.get(k, 0), set2.get(k, 0)) for k in set1.keys() | set2.keys()}\n",
    "\n",
    "def fuzzy_intersection(set1, set2):\n",
    "    return {k: min(set1.get(k, 0), set2.get(k, 0)) for k in set1.keys() & set2.keys()}\n",
    "\n",
    "def fuzzy_complement(set1, universe):\n",
    "    return {k: 1 - set1.get(k, 0) for k in universe}\n",
    "\n",
    "def main():\n",
    "    A = {'x1': 0.8, 'x2': 0.4, 'x3': 0.6}\n",
    "    B = {'x1': 0.5, 'x2': 0.7, 'x3': 0.2}\n",
    "    universe = {'x1', 'x2', 'x3'}\n",
    "    \n",
    "    print(\"Fuzzy Set A:\", A)\n",
    "    print(\"Fuzzy Set B:\", B)\n",
    "    \n",
    "    # De Morgan's Law: (A ∪ B)' = A' ∩ B'\n",
    "    union_AB = fuzzy_union(A, B)\n",
    "    comp_union_AB = fuzzy_complement(union_AB, universe)\n",
    "    comp_A = fuzzy_complement(A, universe)\n",
    "    comp_B = fuzzy_complement(B, universe)\n",
    "    inter_comp_A_B = fuzzy_intersection(comp_A, comp_B)\n",
    "    \n",
    "    print(\"(A ∪ B)':\", comp_union_AB)\n",
    "    print(\"A' ∩ B':\", inter_comp_A_B)\n",
    "    print(\"De Morgan's Law holds:\", comp_union_AB == inter_comp_A_B)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce20ea39-da5f-4681-afaf-ce0f1b16f2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fuzzy Set A: {'x1': 0.8, 'x2': 0.4, 'x3': 0.6}\n",
      "Fuzzy Set B: {'x1': 0.5, 'x2': 0.7, 'x3': 0.2}\n",
      "(A ∩ B)': {'x2': 0.6, 'x3': 0.8, 'x1': 0.5}\n",
      "A' ∪ B': {'x2': 0.6, 'x3': 0.8, 'x1': 0.5}\n",
      "De Morgan's Law holds: True\n"
     ]
    }
   ],
   "source": [
    "# 14. Implement Fuzzy set operations – union, intersection and complement.Demonstrate De Morgan’s Law ( Complement of Intersection) with 2 fuzzy sets. \n",
    "\n",
    "def fuzzy_union(set1, set2):\n",
    "    return {k: max(set1.get(k, 0), set2.get(k, 0)) for k in set1.keys() | set2.keys()}\n",
    "\n",
    "def fuzzy_intersection(set1, set2):\n",
    "    return {k: min(set1.get(k, 0), set2.get(k, 0)) for k in set1.keys() & set2.keys()}\n",
    "\n",
    "def fuzzy_complement(set1, universe):\n",
    "    return {k: 1 - set1.get(k, 0) for k in universe}\n",
    "\n",
    "def main():\n",
    "    A = {'x1': 0.8, 'x2': 0.4, 'x3': 0.6}\n",
    "    B = {'x1': 0.5, 'x2': 0.7, 'x3': 0.2}\n",
    "    universe = {'x1', 'x2', 'x3'}\n",
    "    \n",
    "    print(\"Fuzzy Set A:\", A)\n",
    "    print(\"Fuzzy Set B:\", B)\n",
    "    \n",
    "    # De Morgan's Law: (A ∩ B)' = A' ∪ B'\n",
    "    inter_AB = fuzzy_intersection(A, B)\n",
    "    comp_inter_AB = fuzzy_complement(inter_AB, universe)\n",
    "    comp_A = fuzzy_complement(A, universe)\n",
    "    comp_B = fuzzy_complement(B, universe)\n",
    "    union_comp_A_B = fuzzy_union(comp_A, comp_B)\n",
    "    \n",
    "    print(\"(A ∩ B)':\", comp_inter_AB)\n",
    "    print(\"A' ∪ B':\", union_comp_A_B)\n",
    "    print(\"De Morgan's Law holds:\", comp_inter_AB == union_comp_A_B)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "875e345f-2c9e-47fb-a08a-caf0e9197e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Tic-Tac-Toe!\n",
      " | | \n",
      "-+-+-\n",
      " | | \n",
      "-+-+-\n",
      " | | \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your move (1-9):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computer's move:\n",
      "X| | \n",
      "-+-+-\n",
      " |O| \n",
      "-+-+-\n",
      " | | \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your move (1-9):  9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computer's move:\n",
      "X|O| \n",
      "-+-+-\n",
      " |O| \n",
      "-+-+-\n",
      " | |X\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your move (1-9):  8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computer's move:\n",
      "X|O| \n",
      "-+-+-\n",
      " |O| \n",
      "-+-+-\n",
      "O|X|X\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your move (1-9):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computer's move:\n",
      "X|O|X\n",
      "-+-+-\n",
      " |O|O\n",
      "-+-+-\n",
      "O|X|X\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your move (1-9):  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X|O|X\n",
      "-+-+-\n",
      "X|O|O\n",
      "-+-+-\n",
      "O|X|X\n",
      "It's a draw!\n"
     ]
    }
   ],
   "source": [
    "# 15. Implement any two-player game ( Modified Tic-Tac-Toe, Nim Game,\n",
    "# Connect Four Game or Gomoku Game ) using min-max algorithm such\n",
    "# that in every play either computer wins or it is a draw. \n",
    "\n",
    "import math\n",
    "\n",
    "# Initialize board\n",
    "board = [' ' for _ in range(9)]\n",
    "\n",
    "def print_board(board):\n",
    "    for i in range(3):\n",
    "        print(board[3*i] + \"|\" + board[3*i+1] + \"|\" + board[3*i+2])\n",
    "        if i < 2:\n",
    "            print(\"-+-+-\")\n",
    "\n",
    "def check_winner(board, player):\n",
    "    win_positions = [\n",
    "        (0,1,2), (3,4,5), (6,7,8),  \n",
    "        (0,3,6), (1,4,7), (2,5,8),  \n",
    "        (0,4,8), (2,4,6)            \n",
    "    ]\n",
    "    for pos in win_positions:\n",
    "        if board[pos[0]] == board[pos[1]] == board[pos[2]] == player:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_full(board):\n",
    "    return ' ' not in board\n",
    "\n",
    "# Minimax algorithm\n",
    "def minimax(board, is_maximizing):\n",
    "    if check_winner(board, 'O'):\n",
    "        return 1\n",
    "    if check_winner(board, 'X'):\n",
    "        return -1\n",
    "    if is_full(board):\n",
    "        return 0\n",
    "\n",
    "    if is_maximizing:\n",
    "        best_score = -math.inf\n",
    "        for i in range(9):\n",
    "            if board[i] == ' ':\n",
    "                board[i] = 'O'\n",
    "                score = minimax(board, False)\n",
    "                board[i] = ' '\n",
    "                best_score = max(score, best_score)\n",
    "        return best_score\n",
    "    else:\n",
    "        best_score = math.inf\n",
    "        for i in range(9):\n",
    "            if board[i] == ' ':\n",
    "                board[i] = 'X'\n",
    "                score = minimax(board, True)\n",
    "                board[i] = ' '\n",
    "                best_score = min(score, best_score)\n",
    "        return best_score\n",
    "\n",
    "def computer_move(board):\n",
    "    best_score = -math.inf\n",
    "    move = None\n",
    "    for i in range(9):\n",
    "        if board[i] == ' ':\n",
    "            board[i] = 'O'\n",
    "            score = minimax(board, False)\n",
    "            board[i] = ' '\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                move = i\n",
    "    board[move] = 'O'\n",
    "\n",
    "def play_game():\n",
    "    print(\"Welcome to Tic-Tac-Toe!\")\n",
    "    print_board(board)\n",
    "\n",
    "    while True:\n",
    "        move = int(input(\"Enter your move (1-9): \")) - 1\n",
    "        if board[move] != ' ':\n",
    "            print(\"Invalid move. Try again.\")\n",
    "            continue\n",
    "        board[move] = 'X'\n",
    "\n",
    "        if check_winner(board, 'X'):\n",
    "            print_board(board)\n",
    "            print(\"You win!\")\n",
    "            break\n",
    "\n",
    "        if is_full(board):\n",
    "            print_board(board)\n",
    "            print(\"It's a draw!\")\n",
    "            break\n",
    "\n",
    "        computer_move(board)\n",
    "        print(\"\\nComputer's move:\")\n",
    "        print_board(board)\n",
    "\n",
    "        if check_winner(board, 'O'):\n",
    "            print(\"Computer wins!\")\n",
    "            break\n",
    "\n",
    "        if is_full(board):\n",
    "            print(\"It's a draw!\")\n",
    "            break\n",
    "\n",
    "# Start the game\n",
    "play_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ccdf76b2-f14c-49e8-afcb-03e3cfda4977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Tic-Tac-Toe! (Computer plays badly)\n",
      " | | \n",
      "-+-+-\n",
      " | | \n",
      "-+-+-\n",
      " | | \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your move (1-9):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computer's move:\n",
      "X| | \n",
      "-+-+-\n",
      " |O| \n",
      "-+-+-\n",
      " | | \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your move (1-9):  9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computer's move:\n",
      "X|O| \n",
      "-+-+-\n",
      " |O| \n",
      "-+-+-\n",
      " | |X\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your move (1-9):  8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computer's move:\n",
      "X|O| \n",
      "-+-+-\n",
      " |O| \n",
      "-+-+-\n",
      "O|X|X\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your move (1-9):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computer's move:\n",
      "X|O|X\n",
      "-+-+-\n",
      " |O|O\n",
      "-+-+-\n",
      "O|X|X\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your move (1-9):  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X|O|X\n",
      "-+-+-\n",
      "X|O|O\n",
      "-+-+-\n",
      "O|X|X\n",
      "It's a draw!\n"
     ]
    }
   ],
   "source": [
    "# 16. Implement any two-player game ( Modified Tic-Tac-Toe, Nim Game,\n",
    "# Connect Four Game or Gomoku Game ) using min-max algorithm such\n",
    "# that in every play either computer loses or it is a draw\n",
    "\n",
    "import math\n",
    "\n",
    "board = [' ' for _ in range(9)]\n",
    "\n",
    "def print_board(board):\n",
    "    for i in range(3):\n",
    "        print(board[3*i] + \"|\" + board[3*i+1] + \"|\" + board[3*i+2])\n",
    "        if i < 2:\n",
    "            print(\"-+-+-\")\n",
    "\n",
    "def check_winner(board, player):\n",
    "    win_positions = [\n",
    "        (0,1,2), (3,4,5), (6,7,8),  \n",
    "        (0,3,6), (1,4,7), (2,5,8),  \n",
    "        (0,4,8), (2,4,6)            \n",
    "    ]\n",
    "    for pos in win_positions:\n",
    "        if board[pos[0]] == board[pos[1]] == board[pos[2]] == player:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_full(board):\n",
    "    return ' ' not in board\n",
    "\n",
    "# Minimax algorithm (help human win)\n",
    "def minimax(board, is_computer_turn):\n",
    "    if check_winner(board, 'X'):\n",
    "        return 1  # Human wins\n",
    "    if check_winner(board, 'O'):\n",
    "        return -1  # Computer wins\n",
    "    if is_full(board):\n",
    "        return 0  # Draw\n",
    "\n",
    "    if is_computer_turn:\n",
    "        best_score = math.inf\n",
    "        for i in range(9):\n",
    "            if board[i] == ' ':\n",
    "                board[i] = 'O'\n",
    "                score = minimax(board, False)\n",
    "                board[i] = ' '\n",
    "                best_score = min(score, best_score)\n",
    "        return best_score\n",
    "    else:\n",
    "        best_score = -math.inf\n",
    "        for i in range(9):\n",
    "            if board[i] == ' ':\n",
    "                board[i] = 'X'\n",
    "                score = minimax(board, True)\n",
    "                board[i] = ' '\n",
    "                best_score = max(score, best_score)\n",
    "        return best_score\n",
    "\n",
    "# Computer move (intentionally weak)\n",
    "def computer_move(board):\n",
    "    worst_score = math.inf\n",
    "    move = None\n",
    "    for i in range(9):\n",
    "        if board[i] == ' ':\n",
    "            board[i] = 'O'\n",
    "            score = minimax(board, False)\n",
    "            board[i] = ' '\n",
    "            if score < worst_score:\n",
    "                worst_score = score\n",
    "                move = i\n",
    "    board[move] = 'O'\n",
    "\n",
    "# Main game loop\n",
    "def play_game():\n",
    "    print(\"Welcome to Tic-Tac-Toe! (Computer plays badly)\")\n",
    "    print_board(board)\n",
    "\n",
    "    while True:\n",
    "        # Player move\n",
    "        move = int(input(\"Enter your move (1-9): \")) - 1\n",
    "        if board[move] != ' ':\n",
    "            print(\"Invalid move. Try again.\")\n",
    "            continue\n",
    "        board[move] = 'X'\n",
    "\n",
    "        # Check if player wins\n",
    "        if check_winner(board, 'X'):\n",
    "            print_board(board)\n",
    "            print(\"You win!\")\n",
    "            break\n",
    "\n",
    "        # Check draw\n",
    "        if is_full(board):\n",
    "            print_board(board)\n",
    "            print(\"It's a draw!\")\n",
    "            break\n",
    "\n",
    "        # Computer move\n",
    "        computer_move(board)\n",
    "        print(\"\\nComputer's move:\")\n",
    "        print_board(board)\n",
    "\n",
    "        # Check if computer wins\n",
    "        if check_winner(board, 'O'):\n",
    "            print(\"Computer wins! (very rare)\")\n",
    "            break\n",
    "\n",
    "        # Check draw\n",
    "        if is_full(board):\n",
    "            print(\"It's a draw!\")\n",
    "            break\n",
    "\n",
    "# Start the game\n",
    "play_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06fb5e12-2a18-4e7b-bac1-529c1fa19e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number of inputs:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Weights W1:\n",
      " [[ 0.29686811 -0.17743034  1.25053061  0.06308815]\n",
      " [-0.03242416  0.61039214  0.07234795  0.80746368]]\n",
      "Final Biases B1: [-0.64408504  1.03015788 -0.928676   -0.24203955]\n",
      "Final Weights W2:\n",
      " [[ 0.98483412  0.49930965  0.67544276  2.15609834]\n",
      " [-1.08846413  0.36652017  0.45314052 -0.23379485]\n",
      " [-1.32918792  0.57210768 -0.23526393  1.07604778]\n",
      " [-0.76722007 -1.04616883 -0.31866441  0.07011615]]\n",
      "Final Biases B2: [-0.77744504 -0.64280256  0.66566995  1.43516117]\n",
      "Final Weights W3:\n",
      " [[-0.34833746]\n",
      " [-1.29362171]\n",
      " [-2.41571271]\n",
      " [ 1.05689465]]\n",
      "Final Biases B3: [1.2058613]\n",
      "Steps: 1000\n"
     ]
    }
   ],
   "source": [
    "# 17. Implement a simple Multi-Layer Perceptron with N binary inputs, two hidden layers and one binary output. Display the final weight matrices, bias\n",
    "# values and the number of steps. Note that random values are assigned to weight matrices and bias in each step. \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def mlp_train(inputs, target, n_hidden1, n_hidden2, epochs=1000):\n",
    "    n_inputs = len(inputs[0])\n",
    "    w1 = np.random.randn(n_inputs, n_hidden1)\n",
    "    b1 = np.random.randn(n_hidden1)\n",
    "    w2 = np.random.randn(n_hidden1, n_hidden2)\n",
    "    b2 = np.random.randn(n_hidden2)\n",
    "    w3 = np.random.randn(n_hidden2, 1)\n",
    "    b3 = np.random.randn(1)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass\n",
    "        h1 = sigmoid(np.dot(inputs, w1) + b1)\n",
    "        h2 = sigmoid(np.dot(h1, w2) + b2)\n",
    "        output = sigmoid(np.dot(h2, w3) + b3)\n",
    "        \n",
    "        # Simple update (random for simplicity)\n",
    "        error = np.mean((output - target) ** 2)\n",
    "        if error < 0.01:\n",
    "            break\n",
    "        w1 += np.random.randn(*w1.shape) * 0.01\n",
    "        b1 += np.random.randn(*b1.shape) * 0.01\n",
    "        w2 += np.random.randn(*w2.shape) * 0.01\n",
    "        b2 += np.random.randn(*b2.shape) * 0.01\n",
    "        w3 += np.random.randn(*w3.shape) * 0.01\n",
    "        b3 += np.random.randn(*b3.shape) * 0.01\n",
    "    \n",
    "    return w1, b1, w2, b2, w3, b3, epoch + 1\n",
    "\n",
    "def main():\n",
    "    n = int(input(\"Enter number of inputs: \"))\n",
    "    inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])  # Example for 2 inputs\n",
    "    target = np.array([[0], [1], [1], [0]])  # XOR-like\n",
    "    w1, b1, w2, b2, w3, b3, steps = mlp_train(inputs, target, 4, 4)\n",
    "    print(\"Final Weights W1:\\n\", w1)\n",
    "    print(\"Final Biases B1:\", b1)\n",
    "    print(\"Final Weights W2:\\n\", w2)\n",
    "    print(\"Final Biases B2:\", b2)\n",
    "    print(\"Final Weights W3:\\n\", w3)\n",
    "    print(\"Final Biases B3:\", b3)\n",
    "    print(\"Steps:\", steps)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a194029f-ee05-4785-9c3d-a9b3e26ddbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Weights W1:\n",
      " [[ 2.17746141  0.25003926 -0.19833868  1.6565097 ]\n",
      " [-0.4939328   0.98913609  0.40967405 -1.06671094]\n",
      " [ 0.36401239 -2.24055891  0.52617529  0.94531316]\n",
      " [-1.51516975  1.27861684 -0.15993574  1.84184892]]\n",
      "Final Biases B1: [ 0.24332285 -1.73297197  1.31064093  0.61315346]\n",
      "Final Weights W2:\n",
      " [[-1.2966549   1.09983588]\n",
      " [-0.41155184 -1.05471389]\n",
      " [ 0.54421438 -0.7882773 ]\n",
      " [ 1.37762155  0.30982579]]\n",
      "Final Biases B2: [-0.04956982 -0.11123091]\n",
      "Steps: 1000\n"
     ]
    }
   ],
   "source": [
    "# 18. Implement a simple Multi-Layer Perceptron with 4 binary inputs, one hidden layer and two binary outputs. Display the final weight matrices, bias\n",
    "# values and the number of steps. Note that random values are assigned to weight matrices and bias in each step. \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def mlp_train(inputs, target, n_hidden, epochs=1000):\n",
    "    n_inputs = len(inputs[0])\n",
    "    w1 = np.random.randn(n_inputs, n_hidden)\n",
    "    b1 = np.random.randn(n_hidden)\n",
    "    w2 = np.random.randn(n_hidden, 2)\n",
    "    b2 = np.random.randn(2)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass\n",
    "        h1 = sigmoid(np.dot(inputs, w1) + b1)\n",
    "        output = sigmoid(np.dot(h1, w2) + b2)\n",
    "        \n",
    "        # Simple update\n",
    "        error = np.mean((output - target) ** 2)\n",
    "        if error < 0.01:\n",
    "            break\n",
    "        w1 += np.random.randn(*w1.shape) * 0.01\n",
    "        b1 += np.random.randn(*b1.shape) * 0.01\n",
    "        w2 += np.random.randn(*w2.shape) * 0.01\n",
    "        b2 += np.random.randn(*b2.shape) * 0.01\n",
    "    \n",
    "    return w1, b1, w2, b2, epoch + 1\n",
    "\n",
    "def main():\n",
    "    inputs = np.array([[0, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0], [0, 0, 1, 1]]) \n",
    "    target = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "    w1, b1, w2, b2, steps = mlp_train(inputs, target, 4)\n",
    "    print(\"Final Weights W1:\\n\", w1)\n",
    "    print(\"Final Biases B1:\", b1)\n",
    "    print(\"Final Weights W2:\\n\", w2)\n",
    "    print(\"Final Biases B2:\", b2)\n",
    "    print(\"Steps:\", steps)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "610f575b-8659-4cab-9019-3a22ad2be832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number of inputs:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Weights W1:\n",
      " [[ 0.69598764 -0.34340302 -0.18141699  2.09146907]\n",
      " [-0.7998137  -0.79389671  0.91768441  1.55900912]]\n",
      "Final Biases B1: [ 2.13707375 -2.0338758   1.48020557 -0.27103883]\n",
      "Final Weights W2:\n",
      " [[-1.99115912 -1.98868498 -0.34293221 -1.50036283]\n",
      " [ 0.82356696  0.00821677  1.32350168  1.72406384]\n",
      " [ 0.32405189  0.73157791  1.4836102  -0.26653063]\n",
      " [ 2.08326857  0.3488095  -0.89509433  1.53424146]]\n",
      "Final Biases B2: [0.78193056 0.05862468 0.92794818 1.62484833]\n",
      "Final Weights W3:\n",
      " [[ 1.46218596]\n",
      " [ 1.04293722]\n",
      " [-2.19347484]\n",
      " [-0.00375689]]\n",
      "Final Biases B3: [0.39118766]\n"
     ]
    }
   ],
   "source": [
    "# 19. Implement a simple Multi-Layer Perceptron with N binary inputs, two hidden layers and one output. Use backpropagation and Sigmoid function\n",
    "# as activation function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_deriv(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "def mlp_train(inputs, target, n_hidden1, n_hidden2, epochs=1000, lr=0.1):\n",
    "    n_inputs = len(inputs[0])\n",
    "    w1 = np.random.randn(n_inputs, n_hidden1)\n",
    "    b1 = np.random.randn(n_hidden1)\n",
    "    w2 = np.random.randn(n_hidden1, n_hidden2)\n",
    "    b2 = np.random.randn(n_hidden2)\n",
    "    w3 = np.random.randn(n_hidden2, 1)\n",
    "    b3 = np.random.randn(1)\n",
    "    \n",
    "    for _ in range(epochs):\n",
    "        # Forward\n",
    "        z1 = np.dot(inputs, w1) + b1\n",
    "        h1 = sigmoid(z1)\n",
    "        z2 = np.dot(h1, w2) + b2\n",
    "        h2 = sigmoid(z2)\n",
    "        z3 = np.dot(h2, w3) + b3\n",
    "        output = sigmoid(z3)\n",
    "        \n",
    "        # Backward\n",
    "        error = output - target\n",
    "        delta3 = error * sigmoid_deriv(output)\n",
    "        error_h2 = np.dot(delta3, w3.T)\n",
    "        delta2 = error_h2 * sigmoid_deriv(h2)\n",
    "        error_h1 = np.dot(delta2, w2.T)\n",
    "        delta1 = error_h1 * sigmoid_deriv(h1)\n",
    "        \n",
    "        # Update\n",
    "        w3 -= lr * np.dot(h2.T, delta3)\n",
    "        b3 -= lr * np.sum(delta3, axis=0)\n",
    "        w2 -= lr * np.dot(h1.T, delta2)\n",
    "        b2 -= lr * np.sum(delta2, axis=0)\n",
    "        w1 -= lr * np.dot(inputs.T, delta1)\n",
    "        b1 -= lr * np.sum(delta1, axis=0)\n",
    "    \n",
    "    return w1, b1, w2, b2, w3, b3\n",
    "\n",
    "def main():\n",
    "    n = int(input(\"Enter number of inputs: \"))\n",
    "    inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])  # Example for 2 inputs\n",
    "    target = np.array([[0], [1], [1], [0]])  # XOR-like\n",
    "    w1, b1, w2, b2, w3, b3 = mlp_train(inputs, target, 4, 4)\n",
    "    print(\"Final Weights W1:\\n\", w1)\n",
    "    print(\"Final Biases B1:\", b1)\n",
    "    print(\"Final Weights W2:\\n\", w2)\n",
    "    print(\"Final Biases B2:\", b2)\n",
    "    print(\"Final Weights W3:\\n\", w3)\n",
    "    print(\"Final Biases B3:\", b3)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "424f49d4-4bc3-4558-896e-bab13cbe589e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number of inputs:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Weights W1:\n",
      " [[-1.21088075  0.38091927 -0.25056585 -0.24245423]\n",
      " [-1.39464791  0.43122439  0.6590803   1.55701826]]\n",
      "Final Biases B1: [-1.5812299  -0.59015922  2.21127094  0.07865528]\n",
      "Final Weights W2:\n",
      " [[-0.61223284 -0.09008656  0.61357986 -0.34958252]\n",
      " [-0.8148057   0.88100725 -0.34827611 -0.44077822]\n",
      " [ 0.31516405 -1.010588   -0.03070052 -0.11878813]\n",
      " [-0.14914177  0.34998364  0.66397738 -2.90434764]]\n",
      "Final Biases B2: [ 1.86044185 -0.96350014 -0.28704495  0.01640651]\n",
      "Final Weights W3:\n",
      " [[-0.88115125]\n",
      " [-0.89978117]\n",
      " [-1.37621953]\n",
      " [-0.66556735]]\n",
      "Final Biases B3: [0.86246375]\n"
     ]
    }
   ],
   "source": [
    "# 20. Implement a simple Multi-Layer Perceptron with N binary inputs, two hidden layers and one output. Use backpropagation and ReLU function as\n",
    "# activation function. \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_deriv(x):\n",
    "    return np.where(x > 0, 1, 0)\n",
    "\n",
    "def mlp_train(inputs, target, n_hidden1, n_hidden2, epochs=1000, lr=0.01):\n",
    "    n_inputs = len(inputs[0])\n",
    "    w1 = np.random.randn(n_inputs, n_hidden1)\n",
    "    b1 = np.random.randn(n_hidden1)\n",
    "    w2 = np.random.randn(n_hidden1, n_hidden2)\n",
    "    b2 = np.random.randn(n_hidden2)\n",
    "    w3 = np.random.randn(n_hidden2, 1)\n",
    "    b3 = np.random.randn(1)\n",
    "    \n",
    "    for _ in range(epochs):\n",
    "        # Forward\n",
    "        z1 = np.dot(inputs, w1) + b1\n",
    "        h1 = relu(z1)\n",
    "        z2 = np.dot(h1, w2) + b2\n",
    "        h2 = relu(z2)\n",
    "        z3 = np.dot(h2, w3) + b3\n",
    "        output = relu(z3)\n",
    "        \n",
    "        # Backward\n",
    "        error = output - target\n",
    "        delta3 = error * relu_deriv(output)\n",
    "        error_h2 = np.dot(delta3, w3.T)\n",
    "        delta2 = error_h2 * relu_deriv(h2)\n",
    "        error_h1 = np.dot(delta2, w2.T)\n",
    "        delta1 = error_h1 * relu_deriv(h1)\n",
    "        \n",
    "        # Update\n",
    "        w3 -= lr * np.dot(h2.T, delta3)\n",
    "        b3 -= lr * np.sum(delta3, axis=0)\n",
    "        w2 -= lr * np.dot(h1.T, delta2)\n",
    "        b2 -= lr * np.sum(delta2, axis=0)\n",
    "        w1 -= lr * np.dot(inputs.T, delta1)\n",
    "        b1 -= lr * np.sum(delta1, axis=0)\n",
    "    \n",
    "    return w1, b1, w2, b2, w3, b3\n",
    "\n",
    "def main():\n",
    "    n = int(input(\"Enter number of inputs: \"))\n",
    "    inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])  \n",
    "    target = np.array([[0], [1], [1], [0]]) \n",
    "    w1, b1, w2, b2, w3, b3 = mlp_train(inputs, target, 4, 4)\n",
    "    print(\"Final Weights W1:\\n\", w1)\n",
    "    print(\"Final Biases B1:\", b1)\n",
    "    print(\"Final Weights W2:\\n\", w2)\n",
    "    print(\"Final Biases B2:\", b2)\n",
    "    print(\"Final Weights W3:\\n\", w3)\n",
    "    print(\"Final Biases B3:\", b3)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "219bfc5c-b910-4373-baaa-e735cb8fa14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number of inputs:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Weights W1:\n",
      " [[ 1.37066171 -0.60421971 -0.34179889 -1.65869423]\n",
      " [-1.58105014 -0.41055684  0.64600089  1.32550643]]\n",
      "Final Biases B1: [-0.79108959 -0.82606283 -1.22745137 -0.81104806]\n",
      "Final Weights W2:\n",
      " [[-0.28006095 -1.34055822 -0.0899361   1.51325261]\n",
      " [ 0.89411442  0.7832913  -0.51822854 -1.14412372]\n",
      " [-1.00084686  0.59080615  0.24834576  0.56281678]\n",
      " [-1.80900764 -1.7364352  -0.56965023 -0.73405869]]\n",
      "Final Biases B2: [-0.74907622 -0.1643337   0.80710399 -0.98729506]\n",
      "Final Weights W3:\n",
      " [[-0.74429987]\n",
      " [-1.52760687]\n",
      " [ 0.7168349 ]\n",
      " [ 0.81753544]]\n",
      "Final Biases B3: [1.55849241]\n"
     ]
    }
   ],
   "source": [
    "# 21. Implement a simple Multi-Layer Perceptron with N binary inputs, two hidden layers and one output. Use backpropagation and Tanh function as\n",
    "# activation function. \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_deriv(x):\n",
    "    return 1 - np.tanh(x) ** 2\n",
    "\n",
    "def mlp_train(inputs, target, n_hidden1, n_hidden2, epochs=1000, lr=0.1):\n",
    "    n_inputs = len(inputs[0])\n",
    "    w1 = np.random.randn(n_inputs, n_hidden1)\n",
    "    b1 = np.random.randn(n_hidden1)\n",
    "    w2 = np.random.randn(n_hidden1, n_hidden2)\n",
    "    b2 = np.random.randn(n_hidden2)\n",
    "    w3 = np.random.randn(n_hidden2, 1)\n",
    "    b3 = np.random.randn(1)\n",
    "    \n",
    "    for _ in range(epochs):\n",
    "        # Forward\n",
    "        z1 = np.dot(inputs, w1) + b1\n",
    "        h1 = tanh(z1)\n",
    "        z2 = np.dot(h1, w2) + b2\n",
    "        h2 = tanh(z2)\n",
    "        z3 = np.dot(h2, w3) + b3\n",
    "        output = tanh(z3)\n",
    "        \n",
    "        # Backward\n",
    "        error = output - target\n",
    "        delta3 = error * tanh_deriv(output)\n",
    "        error_h2 = np.dot(delta3, w3.T)\n",
    "        delta2 = error_h2 * tanh_deriv(h2)\n",
    "        error_h1 = np.dot(delta2, w2.T)\n",
    "        delta1 = error_h1 * tanh_deriv(h1)\n",
    "        \n",
    "        # Update\n",
    "        w3 -= lr * np.dot(h2.T, delta3)\n",
    "        b3 -= lr * np.sum(delta3, axis=0)\n",
    "        w2 -= lr * np.dot(h1.T, delta2)\n",
    "        b2 -= lr * np.sum(delta2, axis=0)\n",
    "        w1 -= lr * np.dot(inputs.T, delta1)\n",
    "        b1 -= lr * np.sum(delta1, axis=0)\n",
    "    \n",
    "    return w1, b1, w2, b2, w3, b3\n",
    "\n",
    "def main():\n",
    "    n = int(input(\"Enter number of inputs: \"))\n",
    "    inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])  # Example\n",
    "    target = np.array([[0], [1], [1], [0]])  # XOR-like\n",
    "    w1, b1, w2, b2, w3, b3 = mlp_train(inputs, target, 4, 4)\n",
    "    print(\"Final Weights W1:\\n\", w1)\n",
    "    print(\"Final Biases B1:\", b1)\n",
    "    print(\"Final Weights W2:\\n\", w2)\n",
    "    print(\"Final Biases B2:\", b2)\n",
    "    print(\"Final Weights W3:\\n\", w3)\n",
    "    print(\"Final Biases B3:\", b3)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02b020a4-1c4f-4547-9da5-0e3103f6b57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dhaval\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Dhaval\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dhaval\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Tokens: ['artificial', 'intelligence', 'fascinating', 'field', 'changed', 'way', 'live', 'machine', 'learning', 'key', 'part', 'ai', 'allows', 'computers', 'learn', 'data', 'neutral', 'network', 'powerful', 'tools', 'recognize', 'patterns', 'images', 'text', 'sound', 'deep', 'learning', 'uses', 'many', 'layers', 'neutral', 'network', 'makes', 'effective', 'complex', 'tasks', 'ai', 'used', 'many', 'industries', 'selfdriving', 'cars', 'rely', 'ai', 'navigable', 'roads', 'healthcare', 'ai', 'helps', 'doctors', 'diagnose', 'diseases', 'analyze', 'rays', 'mrs', 'quickly', 'virtual', 'assistants', 'like', 'sir', 'use', 'ai', 'understand', 'speech', 'respond', 'questions', 'seconds', 'however', 'ai', 'challenges', 'bias', 'data', 'lead', 'unfair', 'results', 'example', 'facial', 'recognition', 'may', 'work', 'well', 'people', 'privacy', 'another', 'concern', 'ai', 'systems', 'collect', 'lot', 'data', 'data', 'must', 'protected', 'ethics', 'ai', 'hot', 'topic', 'ai', 'make', 'decisions', 'autonomous', 'weapons', 'scar', 'idea', 'need', 'rules', 'control', 'ai', 'researches', 'working', 'future', 'ai', 'bright', 'years', 'ai', 'could', 'transform', 'education', 'might', 'help', 'students', 'learn', 'faster', 'ai', 'could', 'also', 'solve', 'big', 'problems', 'like', 'climate', 'change', 'must', 'use', 'wisely', 'mistakes', 'ai', 'development', 'could', 'costly', 'conclusion', 'ai', 'gamechanger', 'great', 'potential', 'needs', 'careful', 'handling', 'lets', 'embrace', 'ai', 'stay', 'cautious']\n"
     ]
    }
   ],
   "source": [
    "# 22. Write a program to read a text file with at least 30 sentences and 200 words\n",
    "# and perform the following tasks in the given sequence.\n",
    "# a. Text cleaning by removing punctuation/special characters, numbers and extra white spaces. Use regular expression for the same.\n",
    "# b. Convert text to lowercase\n",
    "# c. Tokenization\n",
    "# d. Remove stop words\n",
    "# e. Correct misspelled words \n",
    "\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def process_text(filename):\n",
    "    # Read file\n",
    "    with open(filename, 'r') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    # a. Clean text\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    \n",
    "    # b. Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # c. Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # d. Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # e. Correct spelling\n",
    "    corrected_tokens = [str(TextBlob(token).correct()) for token in tokens]\n",
    "    \n",
    "    return corrected_tokens\n",
    "\n",
    "def main():\n",
    "    filename = 'input.txt'  \n",
    "    result = process_text(filename)\n",
    "    print(\"Processed Tokens:\", result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "796e652b-edd4-4d26-87d5-681ac7b93ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dhaval\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Dhaval\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed Tokens: ['artifici', 'intelig', 'is', 'a', 'fascin', 'field', 'it', 'ha', 'chang', 'the']\n",
      "Lemmatized Tokens: ['artificial', 'inteligence', 'is', 'a', 'fascinating', 'field', 'it', 'ha', 'changed', 'the']\n",
      "Trigrams: [['artificial', 'inteligence', 'is'], ['inteligence', 'is', 'a'], ['is', 'a', 'fascinating'], ['a', 'fascinating', 'field'], ['fascinating', 'field', 'it']]\n"
     ]
    }
   ],
   "source": [
    "# 23. Write a program to read a text file with at least 30 sentences and 200 words\n",
    "# and perform the following tasks in the given sequence.\n",
    "# a. Text cleaning by removing punctuation/special characters, numbers and extra white spaces. Use regular expression for the same.\n",
    "# b. Convert text to lowercase\n",
    "# c. Stemming and Lemmatization\n",
    "# d. Create a list of 3 consecutive words after lemmatization\n",
    "\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def process_text(filename):\n",
    "    # Read file\n",
    "    with open(filename, 'r') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    # a. Clean text\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # b. Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # c. Stemming and Lemmatization\n",
    "    tokens = word_tokenize(text)\n",
    "    stemmer = PorterStemmer()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmed = [stemmer.stem(token) for token in tokens]\n",
    "    lemmatized = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    # d. Create trigrams\n",
    "    trigrams = [lemmatized[i:i+3] for i in range(len(lemmatized)-2)]\n",
    "    \n",
    "    return stemmed, lemmatized, trigrams\n",
    "\n",
    "def main():\n",
    "    filename = 'input.txt' \n",
    "    stemmed, lemmatized, trigrams = process_text(filename)\n",
    "    print(\"Stemmed Tokens:\", stemmed[:10])\n",
    "    print(\"Lemmatized Tokens:\", lemmatized[:10])\n",
    "    print(\"Trigrams:\", trigrams[:5])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81e47807-83c0-44cd-ba1b-69f97797c20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['2022' '2023' 'accuracy' 'address' 'addressing' 'adjusts' 'age'\n",
      " 'algorithm' 'algorithms' 'also']\n",
      "One-Hot Matrix (first 5 words):\n",
      " [[0 1 0 0 1]\n",
      " [1 0 1 1 0]\n",
      " [0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# 24. Write a program to read a 3 text files on any technical concept with at least 20 sentences and 150 words. Implement one-hot encoding. \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "def one_hot_encoding(filenames):\n",
    "    texts = []\n",
    "    for filename in filenames:\n",
    "        with open(filename, 'r') as file:\n",
    "            texts.append(file.read())\n",
    "    \n",
    "    # Create vocabulary\n",
    "    vectorizer = CountVectorizer(binary=True)\n",
    "    X = vectorizer.fit_transform(texts)\n",
    "    vocab = vectorizer.get_feature_names_out()\n",
    "    one_hot = X.toarray()\n",
    "    \n",
    "    return vocab, one_hot\n",
    "\n",
    "def main():\n",
    "    filenames = ['text1.txt', 'text2.txt', 'text3.txt']  \n",
    "    vocab, one_hot = one_hot_encoding(filenames)\n",
    "    print(\"Vocabulary:\", vocab[:10])\n",
    "    print(\"One-Hot Matrix (first 5 words):\\n\", one_hot[:, :5])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dd819b4-ac08-4a2e-af31-4fbc6d6b4edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['2022' '2023' 'accuracy' 'address' 'addressing' 'adjusts' 'age'\n",
      " 'algorithm' 'algorithms' 'also']\n",
      "Bag of Words Matrix (first 5 words):\n",
      " [[0 1 0 0 1]\n",
      " [1 0 1 1 0]\n",
      " [0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# 25. Write a program to read a 3 text files on a movie review with at least 20 sentences and 150 words. Implement bag of words. \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def bag_of_words(filenames):\n",
    "    texts = []\n",
    "    for filename in filenames:\n",
    "        with open(filename, 'r') as file:\n",
    "            texts.append(file.read())\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(texts)\n",
    "    vocab = vectorizer.get_feature_names_out()\n",
    "    bow = X.toarray()\n",
    "    \n",
    "    return vocab, bow\n",
    "\n",
    "def main():\n",
    "    filenames = ['text1.txt', 'text2.txt', 'text3.txt']  \n",
    "    vocab, bow = bag_of_words(filenames)\n",
    "    print(\"Vocabulary:\", vocab[:10])\n",
    "    print(\"Bag of Words Matrix (first 5 words):\\n\", bow[:, :5])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62347cb1-e366-4bd7-a00a-c6b52bc50dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['2022' '2023' 'accuracy' 'address' 'addressing' 'adjusts' 'age'\n",
      " 'algorithm' 'algorithms' 'also']\n",
      "TF-IDF Matrix (first 5 words):\n",
      " [[0.         0.05198682 0.         0.         0.06835643]\n",
      " [0.06982469 0.         0.06982469 0.06982469 0.        ]\n",
      " [0.         0.05247299 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# 26. Write a program to read a 3 text files a tourist place with at least 20 sentences and 150 words. Implement TF-IDF. \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def tf_idf(filenames):\n",
    "    texts = []\n",
    "    for filename in filenames:\n",
    "        with open(filename, 'r') as file:\n",
    "            texts.append(file.read())\n",
    "    \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(texts)\n",
    "    vocab = vectorizer.get_feature_names_out()\n",
    "    tfidf = X.toarray()\n",
    "    \n",
    "    return vocab, tfidf\n",
    "\n",
    "def main():\n",
    "    filenames = ['text1.txt', 'text2.txt', 'text3.txt']  \n",
    "    vocab, tfidf = tf_idf(filenames)\n",
    "    print(\"Vocabulary:\", vocab[:10])\n",
    "    print(\"TF-IDF Matrix (first 5 words):\\n\", tfidf[:, :5])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
